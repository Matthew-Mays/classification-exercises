{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import prepare\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Start by defining your baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  embarked_Q  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1           0   \n",
       "337         1       1  41.000000      0      0  134.5000      1           0   \n",
       "50          0       3   7.000000      4      1   39.6875      0           0   \n",
       "218         1       1  32.000000      0      0   76.2917      1           0   \n",
       "31          1       1  29.916875      1      0  146.5208      0           0   \n",
       "..        ...     ...        ...    ...    ...       ...    ...         ...   \n",
       "313         0       3  28.000000      0      0    7.8958      1           0   \n",
       "636         0       3  32.000000      0      0    7.9250      1           0   \n",
       "222         0       3  51.000000      0      0    8.0500      1           0   \n",
       "485         0       3  29.916875      3      1   25.4667      0           0   \n",
       "553         1       3  22.000000      0      0    7.2250      1           0   \n",
       "\n",
       "     embarked_S  sex_male  \n",
       "583           0         1  \n",
       "337           0         0  \n",
       "50            1         1  \n",
       "218           0         0  \n",
       "31            0         0  \n",
       "..          ...       ...  \n",
       "313           1         1  \n",
       "636           1         1  \n",
       "222           1         1  \n",
       "485           1         0  \n",
       "553           0         1  \n",
       "\n",
       "[497 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = prepare.prep_titanic()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617706\n",
       "1    0.382294\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts(normalize=True)\n",
    "# If you assume that everyone died without a baseline model you would get a 62% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.07859679e+00 -3.10510561e-02 -5.17601592e-01 -2.04025452e-01\n",
      "   1.66729023e-03 -9.16177527e-01  8.99227745e-01  2.28830240e-01\n",
      "  -2.42572095e+00]]\n",
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'alone', 'embarked_Q',\n",
      "       'embarked_S', 'sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "logit1 = LogisticRegression()\n",
    "\n",
    "X_train1 = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "logit1 = logit1.fit(X_train1, y_train)\n",
    "print(logit1.coef_)\n",
    "print(X_train1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = logit1.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048289738430584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit1.score(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline model has an 80% accuracy which is much more accurate than just assuming everyone died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create another model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03051881  0.00266519 -0.97983178]]\n",
      "Index(['age', 'fare', 'pclass'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train2 = train[['age', 'fare', 'pclass']]\n",
    "\n",
    "logit2 = LogisticRegression()\n",
    "logit2 = logit2.fit(X_train2, y_train)\n",
    "\n",
    "print(logit2.coef_)\n",
    "print(X_train2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716297786720322"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2.score(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model only has a 72% accuracy which isn't as good as the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.66594879e-02  9.02716903e-04 -1.11402368e+00 -2.45878213e+00]]\n",
      "Index(['age', 'fare', 'pclass', 'sex_male'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train3 = train[['age', 'fare', 'pclass', 'sex_male']]\n",
    "\n",
    "logit3 = LogisticRegression()\n",
    "logit3 = logit3.fit(X_train3, y_train)\n",
    "\n",
    "print(logit3.coef_)\n",
    "print(X_train3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987927565392354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3.score(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has an accuracy of ~80% which is roughly on par with the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logit(X_train):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg = logreg.fit(X_train, y_train)\n",
    "    return logreg, logreg.coef_, logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.95701015 -2.40744024 -0.30828946]] 0.7847082494969819\n"
     ]
    }
   ],
   "source": [
    "X_train4 = train[['pclass', 'sex_male', 'alone']]\n",
    "\n",
    "logit4, coefs, acc = my_logit(X_train4)\n",
    "\n",
    "print(coefs, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is only 78% which is still worse than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.12720398 -2.41479961 -0.17176794 -0.02570129]] 0.7967806841046278\n"
     ]
    }
   ],
   "source": [
    "X_train5 = train[['pclass', 'sex_male', 'alone', 'age']]\n",
    "\n",
    "logit5, coefs, acc = my_logit(X_train5)\n",
    "\n",
    "print(coefs, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is also ~80% which is roughly on par with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.37681345]] 0.7847082494969819\n"
     ]
    }
   ],
   "source": [
    "X_train6 = train[['sex_male']]\n",
    "\n",
    "logit6, coefs, acc = my_logit(X_train6)\n",
    "\n",
    "print(coefs, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is only 78% which isn't quite as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My three best models are model 1 (all vars) & 3 (pclass, sex_male, fare, age) & 5 (pclass, sex_male, alone, age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7990654205607477 0.780373831775701 0.7850467289719626\n"
     ]
    }
   ],
   "source": [
    "X_validate1 = validate.drop(columns='survived')\n",
    "X_validate3 = validate[['age', 'fare', 'pclass', 'sex_male']]\n",
    "X_validate5 = validate[['pclass', 'sex_male', 'alone', 'age']]\n",
    "y_validate = validate.survived\n",
    "\n",
    "acc1 = logit1.score(X_validate1, y_validate)\n",
    "acc3 = logit3.score(X_validate3, y_validate)\n",
    "acc5 = logit5.score(X_validate5, y_validate)\n",
    "\n",
    "print(acc1, acc3, acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: All Vars:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       132\n",
      "           1       0.77      0.68      0.72        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.79      0.78      0.78       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "y3: pclass, sex_male, fare, age:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       132\n",
      "           1       0.72      0.70      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.76      0.77       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "y5: pclass, sex_male, alone, age:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       132\n",
      "           1       0.72      0.71      0.72        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.77      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1_pred = logit1.predict(X_validate1)\n",
    "y3_pred = logit3.predict(X_validate3)\n",
    "y5_pred = logit5.predict(X_validate5)\n",
    "\n",
    "print('y1: All Vars:\\n', classification_report(y_validate, y1_pred))\n",
    "print('y3: pclass, sex_male, fare, age:\\n', classification_report(y_validate, y3_pred))\n",
    "print('y5: pclass, sex_male, alone, age:\\n', classification_report(y_validate, y5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is model 1 which has all X variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797752808988764\n",
      "test report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       110\n",
      "           1       0.74      0.74      0.74        68\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.79      0.79       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "test_acc = logit1.score(X_test, y_test)\n",
    "y1_pred = logit1.predict(X_test)\n",
    "\n",
    "print(test_acc)\n",
    "print('test report:\\n', classification_report(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "Continue working in your model file. Add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  embarked_Q  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1           0   \n",
       "337         1       1  41.000000      0      0  134.5000      1           0   \n",
       "50          0       3   7.000000      4      1   39.6875      0           0   \n",
       "218         1       1  32.000000      0      0   76.2917      1           0   \n",
       "31          1       1  29.916875      1      0  146.5208      0           0   \n",
       "..        ...     ...        ...    ...    ...       ...    ...         ...   \n",
       "313         0       3  28.000000      0      0    7.8958      1           0   \n",
       "636         0       3  32.000000      0      0    7.9250      1           0   \n",
       "222         0       3  51.000000      0      0    8.0500      1           0   \n",
       "485         0       3  29.916875      3      1   25.4667      0           0   \n",
       "553         1       3  22.000000      0      0    7.2250      1           0   \n",
       "\n",
       "     embarked_S  sex_male  \n",
       "583           0         1  \n",
       "337           0         0  \n",
       "50            1         1  \n",
       "218           0         0  \n",
       "31            0         0  \n",
       "..          ...       ...  \n",
       "313           1         1  \n",
       "636           1         1  \n",
       "222           1         1  \n",
       "485           1         0  \n",
       "553           0         1  \n",
       "\n",
       "[497 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['pclass', 'sex_male', 'age', 'alone']]\n",
    "y_train = train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(max_depth=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training data: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training data: {:.2f}'.format(clf1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88       307\n",
      "           1       0.96      0.58      0.73       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.87      0.78      0.80       497\n",
      "weighted avg       0.86      0.83      0.82       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302,   5],\n",
       "       [ 79, 111]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.83\n",
      "recall(true positive rate): 0.58\n",
      "false positive rate: 0.02\n",
      "true negative rate: 0.98\n",
      "false negative rate: 0.42\n",
      "precision: 0.96\n",
      "f1-score: 0.73\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred1), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred1)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth = 10, random_state = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=75, splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier with more depth on training set: 0.88\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier with more depth on training set: {:.2f}'.format(clf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.76      0.83       190\n",
      "\n",
      "    accuracy                           0.88       497\n",
      "   macro avg       0.89      0.86      0.87       497\n",
      "weighted avg       0.88      0.88      0.88       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[294,  13],\n",
       "       [ 46, 144]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n",
      "recall(true positive rate): 0.76\n",
      "false positive rate: 0.04\n",
      "true negative rate: 0.96\n",
      "false negative rate: 0.24\n",
      "precision: 0.92\n",
      "f1-score: 0.83\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred2), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred2)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model with more depth performs better on my in-sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'sex_male', 'age', 'alone']]\n",
    "y_validate = validate.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf1.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of first decision tree(max_depth = 5) on validate data is: 0.7710280373831776\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of first decision tree(max_depth = 5) on validate data is: {clf1.score(X_validate, y_validate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       132\n",
      "           1       0.82      0.51      0.63        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.79      0.72      0.73       214\n",
      "weighted avg       0.78      0.77      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of second decision tree(max_depth = 10) on validate data is: 0.7897196261682243\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of second decision tree(max_depth = 10) on validate data is: {clf2.score(X_validate, y_validate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       132\n",
      "           1       0.75      0.67      0.71        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.77      0.77       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is roughly 2% more accurate than the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue working in your model file. Be sure to add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['pclass', 'sex_male', 'age', 'alone']]\n",
    "y_train = train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_train)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9114688128772636"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       307\n",
      "           1       0.91      0.85      0.88       190\n",
      "\n",
      "    accuracy                           0.91       497\n",
      "   macro avg       0.91      0.90      0.91       497\n",
      "weighted avg       0.91      0.91      0.91       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291  16]\n",
      " [ 28 162]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_rf).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n",
      "recall(true positive rate): 0.85\n",
      "false positive rate: 0.05\n",
      "true negative rate: 0.95\n",
      "false negative rate: 0.15\n",
      "precision: 0.91\n",
      "f1-score: 0.88\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_rf), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_rf)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=3, min_samples_leaf=5)\n",
    "rf2 = rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf2 = rf2.predict(X_train)\n",
    "y_pred_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169014084507042"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       307\n",
      "           1       0.85      0.64      0.73       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.83      0.78      0.79       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[285  22]\n",
      " [ 69 121]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_rf2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n",
      "recall(true positive rate): 0.64\n",
      "false positive rate: 0.07\n",
      "true negative rate: 0.93\n",
      "false negative rate: 0.36\n",
      "precision: 0.85\n",
      "f1-score: 0.73\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_rf2), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_rf2)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of model 1 is 10% higher than model 2.\n",
    "- The recall of model 1 is about 11% higher than model 2.\n",
    "- The precision of model 1 is only about 2% higher than model 2.\n",
    "- The f1-score of model 1 is about 16% higher than model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly model 1 performs better on the in-sample data but with a max_depth of 20 it could be overfitting the data.\n",
    "model 2 having a min_samples_leaf of 5 could be underfitting the data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=1, random_state=123)\n",
    "rf3 = rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9114688128772636"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf3 = rf3.predict(X_train)\n",
    "rf3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       307\n",
      "           1       0.91      0.85      0.88       190\n",
      "\n",
      "    accuracy                           0.91       497\n",
      "   macro avg       0.91      0.90      0.91       497\n",
      "weighted avg       0.91      0.91      0.91       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291  16]\n",
      " [ 28 162]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_rf3).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n",
      "recall(true positive rate): 0.85\n",
      "false positive rate: 0.05\n",
      "true negative rate: 0.95\n",
      "false negative rate: 0.15\n",
      "precision: 0.91\n",
      "f1-score: 0.88\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_rf3), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_rf3)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4 = RandomForestClassifier(n_estimators=30, max_depth=10, min_samples_leaf=1)\n",
    "rf4 = rf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf4 = rf4.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054325955734407"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.94      0.81      0.87       190\n",
      "\n",
      "    accuracy                           0.91       497\n",
      "   macro avg       0.91      0.89      0.90       497\n",
      "weighted avg       0.91      0.91      0.90       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[297  10]\n",
      " [ 37 153]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_rf4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_rf4).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n",
      "recall(true positive rate): 0.81\n",
      "false positive rate: 0.03\n",
      "true negative rate: 0.97\n",
      "false negative rate: 0.19\n",
      "precision: 0.94\n",
      "f1-score: 0.87\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_rf4), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_rf4)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far my best 3 models are model 1, model 3, and model 4. So now we try them on validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf1 = rf.predict(X_validate)\n",
    "y_pred_rf3 = rf3.predict(X_validate)\n",
    "y_pred_rf4 = rf4.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       132\n",
      "           1       0.76      0.68      0.72        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.77      0.78       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n",
      "[[114  18]\n",
      " [ 26  56]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred_rf1))\n",
    "print(confusion_matrix(y_validate, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       132\n",
      "           1       0.76      0.68      0.72        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.77      0.78       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n",
      "[[114  18]\n",
      " [ 26  56]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred_rf3))\n",
    "print(confusion_matrix(y_validate, y_pred_rf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       132\n",
      "           1       0.75      0.67      0.71        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.77      0.77       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n",
      "[[114  18]\n",
      " [ 27  55]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred_rf4))\n",
    "print(confusion_matrix(y_validate, y_pred_rf4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue working in your model notebook or python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>age</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sex_male        age  alone\n",
       "583       1         1  36.000000      1\n",
       "337       1         0  41.000000      1\n",
       "50        3         1   7.000000      0\n",
       "218       1         0  32.000000      1\n",
       "31        1         0  29.916875      0\n",
       "..      ...       ...        ...    ...\n",
       "313       3         1  28.000000      1\n",
       "636       3         1  32.000000      1\n",
       "222       3         1  51.000000      1\n",
       "485       3         0  29.916875      0\n",
       "553       3         1  22.000000      1\n",
       "\n",
       "[497 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn1 = knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn1 = knn1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289738430583501"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = knn1.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[273  34]\n",
      " [ 51 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       307\n",
      "           1       0.80      0.73      0.77       190\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.82      0.81      0.82       497\n",
      "weighted avg       0.83      0.83      0.83       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_knn1))\n",
    "print(classification_report(y_train, y_pred_knn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.83\n",
      "recall(true positive rate): 0.73\n",
      "false positive rate: 0.11\n",
      "true negative rate: 0.89\n",
      "false negative rate: 0.27\n",
      "precision: 0.8\n",
      "f1-score: 0.77\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_knn1).ravel()\n",
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_knn1), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_knn1)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "knn2 = knn2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826961770623743"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knn2 = knn2.predict(X_train)\n",
    "acc = knn2.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[288  19]\n",
      " [ 89 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       307\n",
      "           1       0.84      0.53      0.65       190\n",
      "\n",
      "    accuracy                           0.78       497\n",
      "   macro avg       0.80      0.73      0.75       497\n",
      "weighted avg       0.79      0.78      0.77       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_knn2))\n",
    "print(classification_report(y_train, y_pred_knn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.78\n",
      "recall(true positive rate): 0.53\n",
      "false positive rate: 0.06\n",
      "true negative rate: 0.94\n",
      "false negative rate: 0.47\n",
      "precision: 0.84\n",
      "f1-score: 0.65\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_knn2).ravel()\n",
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(tp / (tp + fn), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(tp / (tp + fp), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_knn2), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_knn2)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "knn3 = knn3.fit(X_train, y_train)\n",
    "y_pred_knn3 = knn3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       307\n",
      "           1       0.71      0.39      0.50       190\n",
      "\n",
      "    accuracy                           0.71       497\n",
      "   macro avg       0.71      0.65      0.65       497\n",
      "weighted avg       0.71      0.71      0.68       497\n",
      "\n",
      "[[277  30]\n",
      " [116  74]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_knn3))\n",
    "print(confusion_matrix(y_train, y_pred_knn3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71\n",
      "recall(true positive rate): 0.39\n",
      "false positive rate: 0.1\n",
      "true negative rate: 0.9\n",
      "false negative rate: 0.61\n",
      "precision: 0.71\n",
      "f1-score: 0.5\n",
      "support: [307 190]\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_knn3).ravel()\n",
    "acc = round((tp + tn) / (tp + fp + fn + tn), 2)\n",
    "recall = round(recall_score(y_train, y_pred_knn3), 2)\n",
    "fpr = round(fp / (fp + tn), 2)\n",
    "tnr = round(tn / (fp + tn), 2)\n",
    "fnr = round(fn / (tp + fn), 2)\n",
    "precision = round(precision_score(y_train, y_pred_knn3), 2)\n",
    "f1 = round(f1_score(y_train, y_pred_knn3), 2)\n",
    "p, r, f, support = precision_recall_fscore_support(y_train, y_pred_knn3)\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "print(f'recall(true positive rate): {recall}')\n",
    "print(f'false positive rate: {fpr}')\n",
    "print(f'true negative rate: {tnr}')\n",
    "print(f'false negative rate: {fnr}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'f1-score: {f1}')\n",
    "print(f'support: {support}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
